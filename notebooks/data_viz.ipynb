{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "358e62fb-ff17-490a-8672-62dd1d4a0775",
   "metadata": {},
   "source": [
    "**First run the ```init.sh``` file before running this notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f91fd-98c7-4aa4-b166-bf1c0530858c",
   "metadata": {},
   "source": [
    "## Reading the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84390f47-0d28-4506-8134-ca165cc6bc90",
   "metadata": {},
   "source": [
    "idée : voir l'évolution du réseau avec une animation (à mettre à disposition sur le github?) avec un passage des années."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b44cb0-5424-49ee-a388-9cc771b4140d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path : /home/onyxia/work/citations-network/data\n",
      "figure_path : /home/onyxia/work/citations-network/figures\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "#chemin d'accès\n",
    "directory = os.getcwd()\n",
    "data_path = directory[:directory.rfind('/')] + '/data'\n",
    "figure_path = directory[:directory.rfind('/')] + '/figures'\n",
    "print(f\"data_path : {data_path}\")\n",
    "print(f\"figure_path : {figure_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bcfb2f3-1a24-4a25-986e-8b76db8c6b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import networkx as nx\n",
    "\n",
    "# Load CSVs with Polars (super fast!)\n",
    "nodes_df = pl.read_csv(\"/home/onyxia/work/citations-network/data/raw/nodes/papers.csv\", separator='\\t', truncate_ragged_lines=True, schema_overrides={\"halid\": pl.Utf8})\n",
    "edges_df = pl.read_csv(\"/home/onyxia/work/citations-network/data/raw/edges/paper__cites__paper.csv\",  separator='\\t', truncate_ragged_lines=True, schema_overrides={\"halid\": pl.Utf8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4e0338e-fa0e-438c-8fea-e862b76004f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1: halid\tyear\ttitle\tlang\tdomain\tpaper_idx\n",
      "Line 2: 01907786\t2018\tLe Système Comptable Financier algérien entre les « Full IFRS » et la norme IFRS PME : Etude qualitative de sa mise en oeuvre par les entreprises\tfr\t['shs.gestion']\t0\n"
     ]
    }
   ],
   "source": [
    "#print first two rows\n",
    "with open(\"/home/onyxia/work/citations-network/data/raw/nodes/papers.csv\", 'r') as f:\n",
    "    for i in range(2):  # Change the range if you want more rows\n",
    "        line = f.readline()\n",
    "        print(f\"Line {i + 1}: {line.strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dff671cb-cd24-465b-9e59-05d031dee401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 18662036: 2015\tHeteroatom-doped carbon nanostructures as oxygen reduction reaction catalysts in acidic media: an overview\t\t\t565887\n",
      "Line 18662037: 2011\tElectrooxidation of glycerol studied by combined in situ IR spectroscopy and online mass spectrometry under continuous flow conditions\t\t\t565888\n",
      "Line 18662038: 2002\tElectro-oxidation of glycerol on platinum dispersed in polyaniline matrices\t\t\t565889\n"
     ]
    }
   ],
   "source": [
    "start_line = 18_662_035\n",
    "end_line = 18_662_037\n",
    "\n",
    "with open(\"/home/onyxia/work/citations-network/data/raw/nodes/papers.csv\", 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i < start_line:\n",
    "            continue\n",
    "        if i > end_line:\n",
    "            break\n",
    "        print(f\"Line {i + 1}: {line.strip()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4919242c-99eb-4e96-90a0-4a49a5b5f8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (18_662_037,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>paper_idx</th></tr><tr><td>i64</td></tr></thead><tbody><tr><td>0</td></tr><tr><td>1</td></tr><tr><td>2</td></tr><tr><td>3</td></tr><tr><td>4</td></tr><tr><td>&hellip;</td></tr><tr><td>565885</td></tr><tr><td>565886</td></tr><tr><td>565887</td></tr><tr><td>565888</td></tr><tr><td>565889</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (18_662_037,)\n",
       "Series: 'paper_idx' [i64]\n",
       "[\n",
       "\t0\n",
       "\t1\n",
       "\t2\n",
       "\t3\n",
       "\t4\n",
       "\t…\n",
       "\t565885\n",
       "\t565886\n",
       "\t565887\n",
       "\t565888\n",
       "\t565889\n",
       "]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df['paper_idx']df.filter(df.is_duplicated())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "113037aa-380e-4f6e-9fe5-26abd6cf48a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_pd = nodes_df.to_pandas()\n",
    "edges_pd = edges_df.to_pandas()\n",
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a11fdd2a-f52e-415b-906b-03defd49de6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame index must be unique for orient='index'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Add nodes with attributes\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m nodes = \u001b[43mnodes_pd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpaper_idx\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43morient\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mindex\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m G.add_nodes_from(nodes.items())\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Add edges with attributes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py:2178\u001b[39m, in \u001b[36mDataFrame.to_dict\u001b[39m\u001b[34m(self, orient, into, index)\u001b[39m\n\u001b[32m   2075\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2076\u001b[39m \u001b[33;03mConvert the DataFrame to a dictionary.\u001b[39;00m\n\u001b[32m   2077\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2174\u001b[39m \u001b[33;03m defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\u001b[39;00m\n\u001b[32m   2175\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2176\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmethods\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mto_dict\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_dict\n\u001b[32m-> \u001b[39m\u001b[32m2178\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minto\u001b[49m\u001b[43m=\u001b[49m\u001b[43minto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/core/methods/to_dict.py:242\u001b[39m, in \u001b[36mto_dict\u001b[39m\u001b[34m(df, orient, into, index)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m orient == \u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df.index.is_unique:\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDataFrame index must be unique for orient=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    243\u001b[39m     columns = df.columns.tolist()\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m are_all_object_dtype_cols:\n",
      "\u001b[31mValueError\u001b[39m: DataFrame index must be unique for orient='index'."
     ]
    }
   ],
   "source": [
    "# Add nodes with attributes\n",
    "nodes = nodes_pd.set_index('paper_idx').to_dict(orient='index')\n",
    "G.add_nodes_from(nodes.items())\n",
    "\n",
    "# Add edges with attributes\n",
    "edges = edges_pd.to_dict(orient='records')\n",
    "G.add_edges_from((e['paper_idx'], e['c_paper_idx'], {k: v for k, v in e.items() if k not in ['paper_idx', 'c_paper_idx']}) for e in edges)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae501963-d357-464b-8705-aded7d504b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (490_957, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>halid</th><th>year</th><th>title</th><th>lang</th><th>domain</th><th>paper_idx</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;01907786&quot;</td><td>2018</td><td>&quot;Le Système Comptable Financier…</td><td>&quot;fr&quot;</td><td>&quot;[&#x27;shs.gestion&#x27;]&quot;</td><td>0</td></tr><tr><td>&quot;02029554&quot;</td><td>2018</td><td>&quot;Master Droit européen&quot;</td><td>&quot;fr&quot;</td><td>&quot;[]&quot;</td><td>1</td></tr><tr><td>&quot;01724695&quot;</td><td>2017</td><td>&quot;Inversion methods for the reco…</td><td>&quot;fr&quot;</td><td>&quot;[&#x27;math.math-ap&#x27;, &#x27;math.math-na…</td><td>2</td></tr><tr><td>&quot;01730414&quot;</td><td>2017</td><td>&quot;split jacobians and lower boun…</td><td>&quot;en&quot;</td><td>&quot;[&#x27;math.math-gm&#x27;]&quot;</td><td>3</td></tr><tr><td>&quot;01735234&quot;</td><td>2018</td><td>&quot;Sociotechnique de la presbyaco…</td><td>&quot;fr&quot;</td><td>&quot;[&#x27;shs.socio&#x27;]&quot;</td><td>4</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;00203801&quot;</td><td>2010</td><td>&quot;Profiting in the info-communic…</td><td>&quot;en&quot;</td><td>&quot;[&#x27;shs.eco&#x27;]&quot;</td><td>14715</td></tr><tr><td>&quot;02319006&quot;</td><td>2018</td><td>&quot;Évolution de la représentation…</td><td>&quot;fr&quot;</td><td>&quot;[&#x27;sdv.mhep&#x27;]&quot;</td><td>14716</td></tr><tr><td>&quot;02401065&quot;</td><td>2018</td><td>&quot;Crustal growth and Pan-African…</td><td>&quot;fr&quot;</td><td>&quot;[&#x27;sdu.stu.te&#x27;]&quot;</td><td>14717</td></tr><tr><td>&quot;02414905&quot;</td><td>2019</td><td>&quot;Reasoning about Cognitive Atti…</td><td>&quot;en&quot;</td><td>&quot;[&#x27;info.info-ai&#x27;]&quot;</td><td>14718</td></tr><tr><td>&quot;01784408&quot;</td><td>2016</td><td>&quot;Inter-individual variability a…</td><td>&quot;en&quot;</td><td>&quot;[&#x27;sdv&#x27;]&quot;</td><td>14719</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (490_957, 6)\n",
       "┌──────────┬──────┬─────────────────────────────────┬──────┬──────────────────┬───────────┐\n",
       "│ halid    ┆ year ┆ title                           ┆ lang ┆ domain           ┆ paper_idx │\n",
       "│ ---      ┆ ---  ┆ ---                             ┆ ---  ┆ ---              ┆ ---       │\n",
       "│ str      ┆ i64  ┆ str                             ┆ str  ┆ str              ┆ i64       │\n",
       "╞══════════╪══════╪═════════════════════════════════╪══════╪══════════════════╪═══════════╡\n",
       "│ 01907786 ┆ 2018 ┆ Le Système Comptable Financier… ┆ fr   ┆ ['shs.gestion']  ┆ 0         │\n",
       "│ 02029554 ┆ 2018 ┆ Master Droit européen           ┆ fr   ┆ []               ┆ 1         │\n",
       "│ 01724695 ┆ 2017 ┆ Inversion methods for the reco… ┆ fr   ┆ ['math.math-ap', ┆ 2         │\n",
       "│          ┆      ┆                                 ┆      ┆ 'math.math-na…   ┆           │\n",
       "│ 01730414 ┆ 2017 ┆ split jacobians and lower boun… ┆ en   ┆ ['math.math-gm'] ┆ 3         │\n",
       "│ 01735234 ┆ 2018 ┆ Sociotechnique de la presbyaco… ┆ fr   ┆ ['shs.socio']    ┆ 4         │\n",
       "│ …        ┆ …    ┆ …                               ┆ …    ┆ …                ┆ …         │\n",
       "│ 00203801 ┆ 2010 ┆ Profiting in the info-communic… ┆ en   ┆ ['shs.eco']      ┆ 14715     │\n",
       "│ 02319006 ┆ 2018 ┆ Évolution de la représentation… ┆ fr   ┆ ['sdv.mhep']     ┆ 14716     │\n",
       "│ 02401065 ┆ 2018 ┆ Crustal growth and Pan-African… ┆ fr   ┆ ['sdu.stu.te']   ┆ 14717     │\n",
       "│ 02414905 ┆ 2019 ┆ Reasoning about Cognitive Atti… ┆ en   ┆ ['info.info-ai'] ┆ 14718     │\n",
       "│ 01784408 ┆ 2016 ┆ Inter-individual variability a… ┆ en   ┆ ['sdv']          ┆ 14719     │\n",
       "└──────────┴──────┴─────────────────────────────────┴──────┴──────────────────┴───────────┘"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df.drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b726a43-1567-4235-b9e5-ba80b247674a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (27_932_971, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>paper_idx</th><th>c_paper_idx</th></tr><tr><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>7705</td></tr><tr><td>0</td><td>7706</td></tr><tr><td>0</td><td>7707</td></tr><tr><td>0</td><td>7721</td></tr><tr><td>0</td><td>7728</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>7630</td><td>23412</td></tr><tr><td>7669</td><td>291146</td></tr><tr><td>7669</td><td>291147</td></tr><tr><td>7615</td><td>291148</td></tr><tr><td>7615</td><td>291148</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (27_932_971, 2)\n",
       "┌───────────┬─────────────┐\n",
       "│ paper_idx ┆ c_paper_idx │\n",
       "│ ---       ┆ ---         │\n",
       "│ i64       ┆ i64         │\n",
       "╞═══════════╪═════════════╡\n",
       "│ 0         ┆ 7705        │\n",
       "│ 0         ┆ 7706        │\n",
       "│ 0         ┆ 7707        │\n",
       "│ 0         ┆ 7721        │\n",
       "│ 0         ┆ 7728        │\n",
       "│ …         ┆ …           │\n",
       "│ 7630      ┆ 23412       │\n",
       "│ 7669      ┆ 291146      │\n",
       "│ 7669      ┆ 291147      │\n",
       "│ 7615      ┆ 291148      │\n",
       "│ 7615      ┆ 291148      │\n",
       "└───────────┴─────────────┘"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e508820-355c-4246-bf9a-7d5526cf0b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nulls in 'halid': 18171080\n"
     ]
    }
   ],
   "source": [
    "null_count = nodes_df[\"domain\"].is_null().sum()\n",
    "print(f\"Number of nulls in 'halid': {null_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb898ba0-e7be-4856-9608-f111f1fc0936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__arrow_c_stream__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__dataframe__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__radd__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '_accessors',\n",
       " '_cast_all_from_to',\n",
       " '_comp',\n",
       " '_compare_to_non_df',\n",
       " '_compare_to_other_df',\n",
       " '_df',\n",
       " '_div',\n",
       " '_from_arrow',\n",
       " '_from_pandas',\n",
       " '_from_pydf',\n",
       " '_ipython_key_completions_',\n",
       " '_replace',\n",
       " '_repr_html_',\n",
       " '_row_encode',\n",
       " '_to_metadata',\n",
       " '_to_pandas_with_object_columns',\n",
       " '_to_pandas_without_object_columns',\n",
       " 'approx_n_unique',\n",
       " 'bottom_k',\n",
       " 'cast',\n",
       " 'clear',\n",
       " 'clone',\n",
       " 'collect_schema',\n",
       " 'columns',\n",
       " 'corr',\n",
       " 'count',\n",
       " 'describe',\n",
       " 'deserialize',\n",
       " 'drop',\n",
       " 'drop_in_place',\n",
       " 'drop_nans',\n",
       " 'drop_nulls',\n",
       " 'dtypes',\n",
       " 'equals',\n",
       " 'estimated_size',\n",
       " 'explode',\n",
       " 'extend',\n",
       " 'fill_nan',\n",
       " 'fill_null',\n",
       " 'filter',\n",
       " 'flags',\n",
       " 'fold',\n",
       " 'gather_every',\n",
       " 'get_column',\n",
       " 'get_column_index',\n",
       " 'get_columns',\n",
       " 'glimpse',\n",
       " 'group_by',\n",
       " 'group_by_dynamic',\n",
       " 'hash_rows',\n",
       " 'head',\n",
       " 'height',\n",
       " 'hstack',\n",
       " 'insert_column',\n",
       " 'interpolate',\n",
       " 'is_duplicated',\n",
       " 'is_empty',\n",
       " 'is_unique',\n",
       " 'item',\n",
       " 'iter_columns',\n",
       " 'iter_rows',\n",
       " 'iter_slices',\n",
       " 'join',\n",
       " 'join_asof',\n",
       " 'join_where',\n",
       " 'lazy',\n",
       " 'limit',\n",
       " 'map_rows',\n",
       " 'max',\n",
       " 'max_horizontal',\n",
       " 'mean',\n",
       " 'mean_horizontal',\n",
       " 'median',\n",
       " 'melt',\n",
       " 'merge_sorted',\n",
       " 'min',\n",
       " 'min_horizontal',\n",
       " 'n_chunks',\n",
       " 'n_unique',\n",
       " 'null_count',\n",
       " 'partition_by',\n",
       " 'pipe',\n",
       " 'pivot',\n",
       " 'plot',\n",
       " 'product',\n",
       " 'quantile',\n",
       " 'rechunk',\n",
       " 'remove',\n",
       " 'rename',\n",
       " 'replace_column',\n",
       " 'reverse',\n",
       " 'rolling',\n",
       " 'row',\n",
       " 'rows',\n",
       " 'rows_by_key',\n",
       " 'sample',\n",
       " 'schema',\n",
       " 'select',\n",
       " 'select_seq',\n",
       " 'serialize',\n",
       " 'set_sorted',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'shrink_to_fit',\n",
       " 'slice',\n",
       " 'sort',\n",
       " 'sql',\n",
       " 'std',\n",
       " 'style',\n",
       " 'sum',\n",
       " 'sum_horizontal',\n",
       " 'tail',\n",
       " 'to_arrow',\n",
       " 'to_dict',\n",
       " 'to_dicts',\n",
       " 'to_dummies',\n",
       " 'to_init_repr',\n",
       " 'to_jax',\n",
       " 'to_numpy',\n",
       " 'to_pandas',\n",
       " 'to_series',\n",
       " 'to_struct',\n",
       " 'to_torch',\n",
       " 'top_k',\n",
       " 'transpose',\n",
       " 'unique',\n",
       " 'unnest',\n",
       " 'unpivot',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'upsample',\n",
       " 'var',\n",
       " 'vstack',\n",
       " 'width',\n",
       " 'with_columns',\n",
       " 'with_columns_seq',\n",
       " 'with_row_count',\n",
       " 'with_row_index',\n",
       " 'write_avro',\n",
       " 'write_clipboard',\n",
       " 'write_csv',\n",
       " 'write_database',\n",
       " 'write_delta',\n",
       " 'write_excel',\n",
       " 'write_iceberg',\n",
       " 'write_ipc',\n",
       " 'write_ipc_stream',\n",
       " 'write_json',\n",
       " 'write_ndjson',\n",
       " 'write_parquet']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nodes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81d6cfcd-dbcd-4df5-b0a1-58d2137b7453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 1)\n",
      "┌─────────────────────────────────┐\n",
      "│ halid\tyear\ttitle\tlang\tdomain\tp… │\n",
      "│ ---                             │\n",
      "│ str                             │\n",
      "╞═════════════════════════════════╡\n",
      "│ 01907786\t2018\tLe Système Compt… │\n",
      "│ 02029554\t2018\tMaster Droit eur… │\n",
      "│ 01724695\t2017\tInversion method… │\n",
      "│ 01730414\t2017\tsplit jacobians … │\n",
      "│ 01735234\t2018\tSociotechnique d… │\n",
      "└─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(nodes_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06b298b6-f142-4678-8c60-cfdae92a4d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictio = nodes_df[0].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12309f2f-742c-4f66-878e-d9492b5af781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([shape: (1,)\n",
       "Series: 'halid\tyear\ttitle\tlang\tdomain\tpaper_idx' [str]\n",
       "[\n",
       "\t\"01907786\t2018\tLe Système Compt…\n",
       "]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictio.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c8ee6-d0db-4f22-adbb-80b9f1c4e1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdb22b51-d61d-4a11-841f-c60c4225f688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__arrow_c_stream__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__dataframe__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__radd__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '_accessors',\n",
       " '_cast_all_from_to',\n",
       " '_comp',\n",
       " '_compare_to_non_df',\n",
       " '_compare_to_other_df',\n",
       " '_df',\n",
       " '_div',\n",
       " '_from_arrow',\n",
       " '_from_pandas',\n",
       " '_from_pydf',\n",
       " '_ipython_key_completions_',\n",
       " '_replace',\n",
       " '_repr_html_',\n",
       " '_row_encode',\n",
       " '_to_metadata',\n",
       " '_to_pandas_with_object_columns',\n",
       " '_to_pandas_without_object_columns',\n",
       " 'approx_n_unique',\n",
       " 'bottom_k',\n",
       " 'cast',\n",
       " 'clear',\n",
       " 'clone',\n",
       " 'collect_schema',\n",
       " 'columns',\n",
       " 'corr',\n",
       " 'count',\n",
       " 'describe',\n",
       " 'deserialize',\n",
       " 'drop',\n",
       " 'drop_in_place',\n",
       " 'drop_nans',\n",
       " 'drop_nulls',\n",
       " 'dtypes',\n",
       " 'equals',\n",
       " 'estimated_size',\n",
       " 'explode',\n",
       " 'extend',\n",
       " 'fill_nan',\n",
       " 'fill_null',\n",
       " 'filter',\n",
       " 'flags',\n",
       " 'fold',\n",
       " 'gather_every',\n",
       " 'get_column',\n",
       " 'get_column_index',\n",
       " 'get_columns',\n",
       " 'glimpse',\n",
       " 'group_by',\n",
       " 'group_by_dynamic',\n",
       " 'hash_rows',\n",
       " 'head',\n",
       " 'height',\n",
       " 'hstack',\n",
       " 'insert_column',\n",
       " 'interpolate',\n",
       " 'is_duplicated',\n",
       " 'is_empty',\n",
       " 'is_unique',\n",
       " 'item',\n",
       " 'iter_columns',\n",
       " 'iter_rows',\n",
       " 'iter_slices',\n",
       " 'join',\n",
       " 'join_asof',\n",
       " 'join_where',\n",
       " 'lazy',\n",
       " 'limit',\n",
       " 'map_rows',\n",
       " 'max',\n",
       " 'max_horizontal',\n",
       " 'mean',\n",
       " 'mean_horizontal',\n",
       " 'median',\n",
       " 'melt',\n",
       " 'merge_sorted',\n",
       " 'min',\n",
       " 'min_horizontal',\n",
       " 'n_chunks',\n",
       " 'n_unique',\n",
       " 'null_count',\n",
       " 'partition_by',\n",
       " 'pipe',\n",
       " 'pivot',\n",
       " 'plot',\n",
       " 'product',\n",
       " 'quantile',\n",
       " 'rechunk',\n",
       " 'remove',\n",
       " 'rename',\n",
       " 'replace_column',\n",
       " 'reverse',\n",
       " 'rolling',\n",
       " 'row',\n",
       " 'rows',\n",
       " 'rows_by_key',\n",
       " 'sample',\n",
       " 'schema',\n",
       " 'select',\n",
       " 'select_seq',\n",
       " 'serialize',\n",
       " 'set_sorted',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'shrink_to_fit',\n",
       " 'slice',\n",
       " 'sort',\n",
       " 'sql',\n",
       " 'std',\n",
       " 'style',\n",
       " 'sum',\n",
       " 'sum_horizontal',\n",
       " 'tail',\n",
       " 'to_arrow',\n",
       " 'to_dict',\n",
       " 'to_dicts',\n",
       " 'to_dummies',\n",
       " 'to_init_repr',\n",
       " 'to_jax',\n",
       " 'to_numpy',\n",
       " 'to_pandas',\n",
       " 'to_series',\n",
       " 'to_struct',\n",
       " 'to_torch',\n",
       " 'top_k',\n",
       " 'transpose',\n",
       " 'unique',\n",
       " 'unnest',\n",
       " 'unpivot',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'upsample',\n",
       " 'var',\n",
       " 'vstack',\n",
       " 'width',\n",
       " 'with_columns',\n",
       " 'with_columns_seq',\n",
       " 'with_row_count',\n",
       " 'with_row_index',\n",
       " 'write_avro',\n",
       " 'write_clipboard',\n",
       " 'write_csv',\n",
       " 'write_database',\n",
       " 'write_delta',\n",
       " 'write_excel',\n",
       " 'write_iceberg',\n",
       " 'write_ipc',\n",
       " 'write_ipc_stream',\n",
       " 'write_json',\n",
       " 'write_ndjson',\n",
       " 'write_parquet']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nodes_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ba162-4145-4019-9a6c-f1fea2069a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create NetworkX graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes\n",
    "for row in nodes_df.iter_rows(named=True):\n",
    "    G.add_node(row['id'], **{k: v for k, v in row.items() if k != 'id'})\n",
    "\n",
    "# Add edges\n",
    "for row in edges_df.iter_rows(named=True):\n",
    "    G.add_edge(row['source'], row['target'], **{k: v for k, v in row.items() if k not in ['source', 'target']})\n",
    "\n",
    "print(\"Graph built with\", G.number_of_nodes(), \"nodes and\", G.number_of_edges(), \"edges.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a6b23d2-8e94-4720-b500-4182888c9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSVs\n",
    "#nodes_df = pd.read_csv(f\"{data_path}/raw/nodes/papers.csv\")\n",
    "edges_df = pd.read_csv(f\"{data_path}/raw/edges/paper__cites__paper.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd2b277-26bc-4df9-9d1f-8d865c0d3b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_idx\\tc_paper_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0\\t7705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0\\t7706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0\\t7707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0\\t7721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0\\t7728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27932966</th>\n",
       "      <td>7630\\t23412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27932967</th>\n",
       "      <td>7669\\t291146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27932968</th>\n",
       "      <td>7669\\t291147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27932969</th>\n",
       "      <td>7615\\t291148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27932970</th>\n",
       "      <td>7615\\t291148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27932971 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         paper_idx\\tc_paper_idx\n",
       "0                       0\\t7705\n",
       "1                       0\\t7706\n",
       "2                       0\\t7707\n",
       "3                       0\\t7721\n",
       "4                       0\\t7728\n",
       "...                         ...\n",
       "27932966            7630\\t23412\n",
       "27932967           7669\\t291146\n",
       "27932968           7669\\t291147\n",
       "27932969           7615\\t291148\n",
       "27932970           7615\\t291148\n",
       "\n",
       "[27932971 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af217330-f4cb-40d0-859e-98486632348c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the CSVs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m nodes_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdata_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/raw/nodes/papers.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m edges_df = pd.read_csv(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/raw/edges/paper__cites__paper.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Create a graph (use nx.DiGraph() if it's directed)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a graph (use nx.DiGraph() if it's directed)\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes (and optional attributes)\n",
    "for _, row in nodes_df.iterrows():\n",
    "    G.add_node(row['id'], label=row.get('label'))\n",
    "\n",
    "# Add edges (with optional weight or other attributes)\n",
    "for _, row in edges_df.iterrows():\n",
    "    G.add_edge(row['source'], row['target'], weight=row.get('weight'))\n",
    "\n",
    "# You can now use G!\n",
    "print(\"Nodes:\", G.nodes(data=True))\n",
    "print(\"Edges:\", G.edges(data=True))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
